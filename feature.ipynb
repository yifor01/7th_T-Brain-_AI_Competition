{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-16T15:05:18.823613Z",
     "start_time": "2019-10-16T15:05:17.394765Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "#import pandas_profiling\n",
    "import matplotlib\n",
    "import warnings\n",
    "matplotlib.style.use('ggplot')\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from IPython.display import display\n",
    "import random\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, TimeSeriesSplit, GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-16T15:05:18.833701Z",
     "start_time": "2019-10-16T15:05:18.824607Z"
    }
   },
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df, verbose=True):\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)    \n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-16T15:05:25.371206Z",
     "start_time": "2019-10-16T15:05:18.834581Z"
    }
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "df = train.merge(test,how='outer')\n",
    "df = df.sort_values(by='locdt')\n",
    "del train,test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-16T15:05:26.072892Z",
     "start_time": "2019-10-16T15:05:25.372174Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to 159.39 Mb (55.2% reduction)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "62"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=reduce_mem_usage(df)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-16T15:05:26.076882Z",
     "start_time": "2019-10-16T15:05:26.073890Z"
    }
   },
   "outputs": [],
   "source": [
    "# one times report \n",
    "#train_profiling = pandas_profiling.ProfileReport(train)\n",
    "#test_profiling = pandas_profiling.ProfileReport(test)\n",
    "#train_profiling.to_file('train_profiling.html')\n",
    "#test_profiling.to_file('test_profiling.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-16T15:05:27.294688Z",
     "start_time": "2019-10-16T15:05:26.077879Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NA\n",
      " ----------------------------------------\n",
      "flbmk        0.008385\n",
      "flg_3dsmk    0.008385\n",
      "fraud_ind    0.216967\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# NA ratio\n",
    "print( \"NA\\n\",'--'*20 )\n",
    "print( (df.isnull().sum()[df.isnull().sum()>0]) /df.shape[0] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-16T15:05:27.297703Z",
     "start_time": "2019-10-16T15:05:27.295686Z"
    }
   },
   "outputs": [],
   "source": [
    "# Unique value (all dataset)\n",
    "#print(f'train data size: {df.shape[0]}\\n----------------------')\n",
    "#print('Unique Value\\n----------------------')\n",
    "#for i in df.columns:\n",
    "#    if len(df[i].unique()) < 12:\n",
    "#        print('{}:{}     | {}'.format(i, len(df[i].unique()), df[i].unique()))\n",
    "#    else:\n",
    "#        print('{}: {} '.format(i, len(df[i].unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-16T15:05:27.301669Z",
     "start_time": "2019-10-16T15:05:27.298677Z"
    }
   },
   "outputs": [],
   "source": [
    "# Unique value (test)\n",
    "#print(\n",
    "#    f'test data size: {df[df.fraud_ind.isnull()].shape[0]}\\n----------------------'\n",
    "#)\n",
    "#print('Unique Value\\n----------------------')\n",
    "#for i in df.columns:\n",
    "#    if len(df[df.fraud_ind.isnull()][i].unique()) < 12:\n",
    "#        print('{}:{}     | {}'.format(\n",
    "#            i, len(df[df.fraud_ind.isnull()][i].unique()),\n",
    "#            df[df.fraud_ind.isnull()][i].unique()))\n",
    "#    else:\n",
    "#        print('{}: {} '.format(i, len(df[df.fraud_ind.isnull()][i].unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-16T15:05:27.304688Z",
     "start_time": "2019-10-16T15:05:27.302666Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# relation between covariate variable and response variable\n",
    "#exceptlist = []\n",
    "#for k in df.columns:\n",
    "#    if (len(df[k].unique()) >7)  & (df.dtypes!='object')[k] & (k!='fraud_ind') :\n",
    "#        try:\n",
    "#            fig = plt.figure(figsize=(16,9))\n",
    "#            ax1 = fig.add_subplot(221)\n",
    "#            ax2 = fig.add_subplot(222)\n",
    "#            sns.distplot(df[k][df.fraud_ind==0],label='0',ax=ax1)\n",
    "#            sns.distplot(df[k][df.fraud_ind==1],label='1',ax=ax1)\n",
    "#            ax1.legend()\n",
    "#            ax1.set_title(k+' (train)',zcolor='r')\n",
    "#            sns.distplot(df[k][df.fraud_ind.isnull()],label='test',ax=ax2)\n",
    "#            sns.distplot(df[k][df.fraud_ind.notnull()],label='train',ax=ax2)\n",
    "#            ax2.legend()\n",
    "#            ax2.set_title(k,color='r')\n",
    "#        except:\n",
    "#            print('{}: type error -- {}'.format(k,df[k].dtypes))\n",
    "#    elif k=='fraud_ind':\n",
    "#        continue\n",
    "#    else:\n",
    "#        exceptlist.append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-16T15:05:27.308674Z",
     "start_time": "2019-10-16T15:05:27.305658Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#for k in exceptlist:\n",
    "#    display(pd.crosstab(df[df.fraud_ind.notnull()][k],df['fraud_ind'], margins=True, margins_name=\"Total\" ).apply(lambda r: r/df[df.fraud_ind.notnull()].shape[0] , axis=1))\n",
    "#    #display(pd.crosstab(df[df.fraud_ind.notnull()][k],df['fraud_ind']))\n",
    "#    print('--'*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-16T15:05:27.311642Z",
     "start_time": "2019-10-16T15:05:27.309648Z"
    }
   },
   "outputs": [],
   "source": [
    "#viplist = ['cano','conam','csmcu','etymd','locdt','loctm','mcc','mchno','txkey']\n",
    "#for k in viplist:\n",
    "#    if len(df[k].unique() ) < 20:\n",
    "#        \n",
    "#        display(pd.crosstab(df[df.fraud_ind.notnull()][k],df['fraud_ind']))\n",
    "#        print('--'*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-16T15:05:27.313662Z",
     "start_time": "2019-10-16T15:05:27.312640Z"
    }
   },
   "outputs": [],
   "source": [
    "#df[df.fraud_ind.notnull()][['locdt','loctm']].sort_values(by=['locdt','loctm'])\n",
    "#display(df[df.fraud_ind.notnull()][['locdt','loctm']].describe().round(3))\n",
    "#display(df[df.fraud_ind.isnull()][['locdt','loctm']].describe().round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-16T15:05:27.317651Z",
     "start_time": "2019-10-16T15:05:27.314634Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#df[['bacno','acqic','conam','ecfg','locdt','loctm','mcc','mchno','txkey','fraud_ind']]\\\n",
    "#    [df.cano==195350].sort_values(by=['bacno','loctm','locdt'])#\\\n",
    "#    #.groupby('ecfg').fraud_ind.sum()\n",
    "\n",
    "#target_value = 38818\n",
    "#print('---- fraud_ind count ----')\n",
    "#display(df[df.bacno==target_value].sort_values(by=['bacno','loctm','locdt'])\\\n",
    "#        .groupby(['cano','ecfg','stscd','acqic']).fraud_ind.sum())\n",
    "#        #.groupby(['cano','ecfg','stscd','acqic']).fraud_ind.mean())\n",
    "#print('--'*20)\n",
    "#df['count_1'] = 1\n",
    "#print('---- count_1 ----')\n",
    "#display(df[df.bacno==target_value].sort_values(by=['bacno','loctm','locdt'])\\\n",
    "#        .groupby(['cano','ecfg','stscd','acqic']).count_1.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-16T15:05:27.320633Z",
     "start_time": "2019-10-16T15:05:27.318624Z"
    }
   },
   "outputs": [],
   "source": [
    "#target_columns = 'stocn'\n",
    "#\n",
    "#analysis = \\\n",
    "#pd.DataFrame({target_columns:df[df.fraud_ind.notnull()].groupby(target_columns).fraud_ind.mean().index,\n",
    "#              'y_mean':df[df.fraud_ind.notnull()].groupby(target_columns).fraud_ind.mean(),\n",
    "#              'y_count':(df[df.fraud_ind.notnull()].groupby(target_columns).fraud_ind.sum()).astype('int'),\n",
    "#              'size_1':df[df.fraud_ind.notnull()].groupby(target_columns).count_1.sum()\n",
    "#             }).sort_values(by=['size_1','y_mean'],ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-16T15:05:27.324608Z",
     "start_time": "2019-10-16T15:05:27.321617Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#analysis.sort_values(by=['y_mean'],ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Extending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-16T15:05:29.263684Z",
     "start_time": "2019-10-16T15:05:27.325605Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train cano size:  129413\n",
      "test cano size :  86808\n",
      "both cano size :  3763\n",
      "diff cano rate :  0.08256740266541901\n",
      "----------------------------------------\n",
      "train bacno size:  95214\n",
      "test bacno size :  71099\n",
      "both bacno size :  3128\n",
      "diff bacno rate :  0.06051175361597911\n"
     ]
    }
   ],
   "source": [
    "# Check train & test different\n",
    "print('train cano size: ', len(df[df.fraud_ind.notnull()].cano.unique()))\n",
    "print('test cano size : ', len(df[df.fraud_ind.isnull()].cano.unique()))\n",
    "print('both cano size : ',len(set(df[df.fraud_ind.notnull()].cano) & \\\n",
    "                              set(df[df.fraud_ind.isnull()].cano)) )\n",
    "print('diff cano rate : ',len(set(df[df.fraud_ind.notnull()].cano).\\\n",
    "                              difference(set(df[df.fraud_ind.isnull()].cano))) /len(df[df.fraud_ind.notnull()].cano) )\n",
    "print('--' * 20)\n",
    "print('train bacno size: ', len(df[df.fraud_ind.notnull()].bacno.unique()))\n",
    "print('test bacno size : ', len(df[df.fraud_ind.isnull()].bacno.unique()))\n",
    "print('both bacno size : ',len(set(df[df.fraud_ind.notnull()].bacno) & \\\n",
    "                              set(df[df.fraud_ind.isnull()].bacno)) )\n",
    "print('diff bacno rate : ',len(set(df[df.fraud_ind.notnull()].bacno).\\\n",
    "                              difference(set(df[df.fraud_ind.isnull()].bacno)))/len(df[df.fraud_ind.notnull()].bacno) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-16T15:05:29.267673Z",
     "start_time": "2019-10-16T15:05:29.264681Z"
    }
   },
   "outputs": [],
   "source": [
    "# Check train & test different\n",
    "#target_mean_feature = ['csmcu','etymd','mcc','mchno','scity','stocn','stscd']\n",
    "#\n",
    "#for k in target_mean_feature:\n",
    "#    print('train {} size: '.format(k),len(df[df.fraud_ind.notnull()][k]))\n",
    "#    print('test {} size : '.format(k),len(df[df.fraud_ind.isnull()][k]))\n",
    "#    print('both {} size : '.format(k),len(set(df[df.fraud_ind.notnull()][k]) & \\\n",
    "#                                  set(df[df.fraud_ind.isnull()][k])) )\n",
    "#    print('diff {} rate : '.format(k),len(set(df[df.fraud_ind.notnull()][k]).\\\n",
    "#                                  difference(set(df[df.fraud_ind.isnull()][k]))) /\\\n",
    "#                                  len(df[df.fraud_ind.notnull()][k]) )\n",
    "#    print('--'*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-16T15:06:18.139536Z",
     "start_time": "2019-10-16T15:05:29.870097Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: (1943452, 30)\n",
      "acqic: 3118\n",
      "cano_diff: 1\n",
      "csmcu: 10\n",
      "bacno_diff: 2\n",
      "scity: 3428\n",
      "mcc: 62\n",
      "mchno: 51066\n",
      "After: (1788693, 30)\n"
     ]
    }
   ],
   "source": [
    "# transfor data\n",
    "df['cano_diff'] = df.groupby('cano').locdt.shift(0) - df.groupby('cano').locdt.shift(1)\n",
    "df['bacno_diff'] = df.groupby('bacno').locdt.shift(0) - df.groupby('bacno').locdt.shift(1)\n",
    "\n",
    "df['locdt_dtran'] = df['locdt'] % 7\n",
    "df['locdt_mtran'] = df['locdt'] % 30\n",
    "df['loctm'] = df['loctm'] // 10000 + (df['loctm'] -\n",
    "                                      (df['loctm'] // 10000) * 10000) / 6000\n",
    "\n",
    "end = np.array(sorted(df[df.locdt == 120].txkey.values))\n",
    "df['magic_txkey'] = df['txkey'].apply(lambda x: np.where(x <= end)[0][0])\n",
    "# quantitle\n",
    "df['magic_quant'] = df.groupby('magic_txkey').txkey.rank() / df['magic_txkey'].map(df['magic_txkey'].value_counts())\n",
    "df['magic_tm'] = df.magic_txkey.map(df.groupby('magic_txkey').fraud_ind.mean())\n",
    "cat_feature = [x for x in df.columns if x not in ['conam', 'loctm', 'txkey', 'fraud_ind', 'magic_quant', 'magic_tm']]\n",
    "\n",
    "# Check train category not use in test\n",
    "print(f'Before: {df.shape}')\n",
    "for i in set(cat_feature).difference(['cano', 'locdt', 'bacno']):\n",
    "    if len(\n",
    "            set(df[df.fraud_ind.notnull()][i].unique()).difference(\n",
    "                set(df[df.fraud_ind.isnull()][i].unique()))) > 0:\n",
    "        drop_target = list(\n",
    "            set(df[df.fraud_ind.notnull()][i].unique()).difference(\n",
    "                set(df[df.fraud_ind.isnull()][i].unique())))\n",
    "        print(f'{i}: {len(drop_target)}')\n",
    "        df = df.drop(df[df[i].isin(drop_target)].index)\n",
    "print(f'After: {df.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-16T15:06:25.738481Z",
     "start_time": "2019-10-16T15:06:18.139536Z"
    }
   },
   "outputs": [],
   "source": [
    "#target_mean_feature = ['bacno','cano','acqic','csmcu','etymd','mcc','mchno','scity','stocn','stscd']\n",
    "target_mean_feature = ['csmcu', 'etymd', 'mcc', 'stocn', 'magic_txkey']\n",
    "onehot_feature = [\n",
    "    'contp', 'flbmk', 'ecfg', 'flg_3dsmk', 'hcefg', 'insfg', 'ovrlt', 'stscd',\n",
    "    'locdt_dtran', 'iterm'\n",
    "]\n",
    "freq_feature = [\n",
    "    'csmcu', 'etymd', 'mcc', 'mchno', 'acqic', 'bacno', 'cano', 'scity',\n",
    "    'stocn'\n",
    "]\n",
    "\n",
    "for k in target_mean_feature:\n",
    "    df[k + '_tm'] = df[k].map(df.groupby(k).fraud_ind.mean())\n",
    "    df[k + '_ts'] = df[k].map(df.groupby(k).fraud_ind.std()).fillna(0)\n",
    "    df[k + '_keym'] = df[k].map(df.groupby(k).txkey.mean())\n",
    "    df[k + '_keys'] = df[k].map(df.groupby(k).txkey.std()).fillna(0)\n",
    "\n",
    "for k in freq_feature:\n",
    "    df[k + '_f'] = df[k].map(df[k].value_counts(normalize=True))\n",
    "\n",
    "for k in onehot_feature:\n",
    "    add_dumy = pd.get_dummies(df[k])\n",
    "    add_dumy.columns = [k + \"_{}\".format(x) for x in add_dumy.columns]\n",
    "    if add_dumy.shape[0] < 2:\n",
    "        add_dumy = add_dumy.iloc[:, 0]\n",
    "    df = pd.concat([df, add_dumy], axis=1)\n",
    "# fix loctm\n",
    "df['loctm'] = df['loctm'] // 10000 + (df['loctm'] -\n",
    "                                      (df['loctm'] // 10000) * 10000) / 6000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-16T15:07:30.355606Z",
     "start_time": "2019-10-16T15:06:25.739478Z"
    }
   },
   "outputs": [],
   "source": [
    "# conam 相關\n",
    "for k in cat_feature:\n",
    "    df[k + \"_conam_min\"] = df[k].map(df.groupby(k).conam.min())\n",
    "    df[k + \"_conam_max\"] = df[k].map(df.groupby(k).conam.max())\n",
    "    df[k + \"_conam_med\"] = df[k].map(df.groupby(k).conam.median())\n",
    "    df[k + \"_conam_mean\"] = df[k].map(df.groupby(k).conam.mean())\n",
    "    df[k + \"_conam_std\"] = df[k].map(df.groupby(k).conam.std()).fillna(0)\n",
    "    df[k + \"_conam_mean_ratio\"] = df.conam / df[k + \"_conam_mean\"]\n",
    "    df[k + \"_conam_std_ratio\"] = df.conam / df[k + \"_conam_std\"]\n",
    "    del df[k+\"_conam_mean\"] ,df[k+\"_conam_std\"]\n",
    "\n",
    "# txkey 相關\n",
    "for k in cat_feature:\n",
    "    df[k + \"_txkey_min\"] = df[k].map(df.groupby(k).magic_txkey.min())\n",
    "    df[k + \"_txkey_max\"] = df[k].map(df.groupby(k).magic_txkey.max())\n",
    "    df[k + \"_txkey_med\"] = df[k].map(df.groupby(k).magic_txkey.median())\n",
    "    df[k + \"_txkey_mean\"] = df[k].map(df.groupby(k).magic_txkey.mean())\n",
    "    df[k + \"_txkey_std\"] = df[k].map(df.groupby(k).magic_txkey.std()).fillna(0)\n",
    "    df[k + \"_txkey_mean_ratio\"] = df.conam / df[k + \"_txkey_mean\"]\n",
    "    df[k + \"_txkey_med_ratio\"] = df.conam / df[k + \"_txkey_med\"]\n",
    "    df[k + \"_txkey_std_ratio\"] = df.conam / df[k + \"_txkey_std\"]\n",
    "    del df[k+\"_txkey_mean\"] ,df[k+\"_txkey_std\"],df[k+\"_txkey_med\"]\n",
    "\n",
    "df['digital'] = (df.conam - df.conam.astype('int')) * 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-16T15:08:28.793112Z",
     "start_time": "2019-10-16T15:07:30.356603Z"
    }
   },
   "outputs": [],
   "source": [
    "# Might be overfit feature\n",
    "df['test1'] = df.cano.map(df.groupby('cano').magic_txkey.median())\n",
    "df['test2'] = df.bacno.map(df.groupby('bacno').magic_txkey.median())\n",
    "df['test5'] = df.sort_values(by=['cano', 'locdt']).groupby('cano').locdt.diff()\n",
    "\n",
    "# Kaggle feature\n",
    "#df['mean_last'] = df['conam'] - df.groupby('cano')['conam'].transform(lambda x: x.rolling(5, 1).mean())\n",
    "#df['min_last'] = df.groupby('cano')['conam'].transform(lambda x: x.rolling(5, 1).min())\n",
    "#df['max_last'] = df.groupby('cano')['conam'].transform(lambda x: x.rolling(5, 1).max())\n",
    "#df['std_last'] = df['mean_last'] / df.groupby('cano')['conam'].transform(lambda x: x.rolling(5, 1).std())\n",
    "#df['count_last'] = df.groupby('cano')['conam'].transform(lambda x: x.rolling(10, 1).count())\n",
    "#df['mean_last'].fillna(0, inplace=True)\n",
    "#df['std_last'].fillna(0, inplace=True)\n",
    "\n",
    "# card use ratio \n",
    "df['use_card'] = df['cano'].map(df['cano'].value_counts() )/ df['bacno'].map(df['bacno'].value_counts() )\n",
    "\n",
    "### TS ###\n",
    "# csmcu target mean  (train:72 , all:76)\n",
    "df['csmcu_tm1'] = df.csmcu.map(df.groupby('csmcu').fraud_ind.mean())\n",
    "df['firstcard_fraud']= df.cano.map(df.sort_values(by='locdt').groupby('cano').fraud_ind.first())\n",
    "\n",
    "df['cano_csmcu_count'] = df.cano.map(df.groupby('cano').csmcu.count())\n",
    "temp2 = df.groupby('cano').csmcu.value_counts(normalize=True).reset_index(name='cano_csmcu_valuecount')\n",
    "df = df.merge(temp2,how='left',on=['cano','csmcu'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-10-16T15:05:17.426Z"
    }
   },
   "outputs": [],
   "source": [
    "temp1 = df.groupby(['insfg', 'iterm']).fraud_ind.mean().reset_index()\n",
    "temp1.columns.values[2] = 'insfg_iterm_tm'\n",
    "df = df.merge(temp1, how='left')\n",
    "df = reduce_mem_usage(df)\n",
    "del temp1, temp2, add_dumy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-10-16T15:05:17.427Z"
    }
   },
   "outputs": [],
   "source": [
    "#df.to_csv('df.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-10-16T15:05:17.428Z"
    }
   },
   "outputs": [],
   "source": [
    "# find valid set split method\n",
    "#sns.distplot(df[df.fraud_ind==1].locdt,color='r')\n",
    "#sns.distplot(df[df.fraud_ind==0].locdt,color='b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-10-16T15:05:17.429Z"
    }
   },
   "outputs": [],
   "source": [
    "#sns.distplot(df[df.fraud_ind.notnull()].locdt,color='b')\n",
    "#sns.distplot(df[df.fraud_ind.isnull()].locdt,color='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-10-16T15:05:17.430Z"
    }
   },
   "outputs": [],
   "source": [
    "# train and test same cano\n",
    "#cheat_cano = set(df.cano[df.fraud_ind.notnull()]) & set(df.cano[df.fraud_ind.isnull()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-10-16T15:05:17.432Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#temp1 = df[df.cano.isin(cheat_cano)].sort_values(by=['cano','loctm','locdt'])[['bacno','cano','conam','loctm','locdt','fraud_ind']]\n",
    "#temp1[temp1.bacno.isin(temp1.bacno[temp1.fraud_ind==1].unique())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-10-16T15:05:17.433Z"
    }
   },
   "outputs": [],
   "source": [
    "#sns.countplot( df.stocn[(df.fraud_ind==1) &(df.stocn<50) ],color='r' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-10-16T15:05:17.434Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#mat1 = np.zeros([len(df[df.fraud_ind.notnull()].stocn.unique()),5])\n",
    "#count=0\n",
    "#for i in df[df.fraud_ind.notnull()].stocn.unique():\n",
    "#    mat1[count,0] = i\n",
    "#    mat1[count,1] = len(df.stocn[(df.fraud_ind==1) &(df.stocn==i)]  )\n",
    "#    mat1[count,2] = len(df.stocn[(df.fraud_ind==0) &(df.stocn==i)]  )\n",
    "#    mat1[count,3] = len(df.stocn[(df.fraud_ind.isnull()) &(df.stocn==i)]  )\n",
    "#    mat1[count,4] = len(df.stocn[(df.fraud_ind==1) &(df.stocn==i)]  )/\\\n",
    "#        len(df.stocn[(df.stocn==i) & (df.fraud_ind.notnull())]  )\n",
    "#    count+=1\n",
    "#\n",
    "#mat1 = pd.DataFrame(mat1)\n",
    "#mat1.columns = ['stocn','isfraud','nofraud','testset_size','ratio']\n",
    "#mat1.sort_values(by=['testset_size'],ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-10-16T15:05:17.435Z"
    }
   },
   "outputs": [],
   "source": [
    "print(f'test set  size : {df[df.fraud_ind.isnull()].shape[0] }')\n",
    "print(f'test size bcno : {len(df[df.fraud_ind.isnull()].bacno.unique())}')\n",
    "print(f'test size cano : {len(df[df.fraud_ind.isnull()].cano.unique())}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-10-16T15:05:17.437Z"
    }
   },
   "outputs": [],
   "source": [
    "#import lightgbm as lgb\n",
    "from sklearn.metrics import f1_score\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV \n",
    "from xgboost.sklearn import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-10-16T15:05:17.438Z"
    }
   },
   "outputs": [],
   "source": [
    "#feature = [x for x in df.columns if x not in \\\n",
    "#            onehot_feature + freq_feature+['count_1','fraud_ind','locdt','txkey']]\n",
    "#X = df[df.fraud_ind.notnull()][feature]\n",
    "#y = df[df.fraud_ind.notnull()]['fraud_ind'].values.astype('int') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-10-16T15:05:17.439Z"
    }
   },
   "outputs": [],
   "source": [
    "# Do oversampling\n",
    "#new_X = X.copy()\n",
    "#new_y = y.copy()\n",
    "#\n",
    "#add_num = (y==1).sum()\n",
    "#for i in range(74):\n",
    "#    new_X = pd.concat([new_X,X[y==1] ],axis=0)\n",
    "#    new_y = np.append(new_y,[1]*add_num )\n",
    "#    print(f'{i+1}/74',end='\\r')\n",
    "#print('Oversampling OK ....')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-10-16T15:05:17.440Z"
    }
   },
   "outputs": [],
   "source": [
    "def split_data(method=1):\n",
    "    # random split (X)\n",
    "    if method == 1:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2, stratify=y,random_state = 123)\n",
    "    # by cano (O)\n",
    "    elif method == 2:\n",
    "        q_index = df[df.fraud_ind.notnull()].groupby('cano').fraud_ind.mean()\n",
    "        q_index[q_index>0] = 1\n",
    "        tt_idx = random.choices(q_index[q_index==0].index , k = np.int_(len(q_index[q_index==0])*0.8)) +\\\n",
    "            random.choices(q_index[q_index==1].index , k = np.int_(len(q_index[q_index==1])*0.8)) \n",
    "        vv_idx = list(set(q_index.index).difference(tt_idx))\n",
    "        X_train = df[(df.fraud_ind.notnull()) & (df.cano.isin(tt_idx)) ][feature]\n",
    "        y_train = df[(df.fraud_ind.notnull()) & (df.cano.isin(tt_idx)) ]['fraud_ind'].values.astype('int') \n",
    "        X_test = df[(df.fraud_ind.notnull()) & (df.cano.isin(vv_idx)) ][feature]\n",
    "        y_test = df[(df.fraud_ind.notnull()) & (df.cano.isin(vv_idx)) ]['fraud_ind'].values.astype('int') \n",
    "    # by locdt day (X)\n",
    "    elif method==3:\n",
    "        tt_idx = []\n",
    "        for i in range(1,91):\n",
    "            num = df[df.locdt==i].shape[0]\n",
    "            cand = random.sample( list(df[df.locdt==i].index) , np.int_(num*0.8) )\n",
    "            tt_idx+= cand\n",
    "        vv_idx = list(set(df[df.fraud_ind.notnull()].index).difference(tt_idx))\n",
    "        X_train = df[(df.fraud_ind.notnull()) & (df.index.isin(tt_idx)) ][feature]\n",
    "        y_train = df[(df.fraud_ind.notnull()) & (df.index.isin(tt_idx)) ]['fraud_ind'].values.astype('int') \n",
    "        X_test = df[(df.fraud_ind.notnull()) & (df.index.isin(vv_idx)) ][feature]\n",
    "        y_test = df[(df.fraud_ind.notnull()) & (df.index.isin(vv_idx)) ]['fraud_ind'].values.astype('int') \n",
    "    # sliding windows\n",
    "    elif method==4: \n",
    "        X_train = df[(df.fraud_ind.notnull()) & (df.locdt<=66) ][feature]\n",
    "        y_train = df[(df.fraud_ind.notnull()) & (df.locdt<=66) ]['fraud_ind'].values.astype('int') \n",
    "        X_test = df[(df.fraud_ind.notnull()) & (df.locdt>66) ][feature]\n",
    "        y_test = df[(df.fraud_ind.notnull()) & (df.locdt>66) ]['fraud_ind'].values.astype('int') \n",
    "        \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-10-16T15:05:17.441Z"
    }
   },
   "outputs": [],
   "source": [
    "def model_(x_train,y_train,x_test,y_test,boost_type='lgb'):\n",
    "    tStart = time.time()\n",
    "    if boost_type=='lgb':\n",
    "        model = lgb.LGBMClassifier(\n",
    "            boosting_type='gbdt',\n",
    "            objective='binary',\n",
    "            learning_rate=0.01, \n",
    "            n_estimators= 9000, \n",
    "            max_depth = 8, \n",
    "            min_child_weight = 5,       \n",
    "            scale_pos_weight = 9, # refer: 70\n",
    "            subsample = 0.7,\n",
    "            colsample_bytree = 0.7,\n",
    "            subsample_freq =1,\n",
    "            n_jobs=-1)\n",
    "        \n",
    "    elif boost_type=='xgb':\n",
    "        model = XGBClassifier(\n",
    "            learning_rate = 0.03 , \n",
    "            tree_method = 'gpu_hist',\n",
    "            n_estimators=9000, \n",
    "            max_depth=12,\n",
    "            min_child_weight=12, \n",
    "            gamma=0, \n",
    "            subsample=0.8, \n",
    "            colsample_bytree=0.8,\n",
    "            objective= 'binary:logistic', \n",
    "            nthread=-1, \n",
    "            scale_pos_weight=75, \n",
    "            seed=599\n",
    "            )\n",
    "        \n",
    "    print('Start training ...')\n",
    "    model.fit(x_train,y_train)\n",
    "    yp_train = model.predict_proba(x_train)[:,1]\n",
    "    yp_valid = model.predict_proba(x_test)[:,1]\n",
    "    print(f'Use time: { np.int_((time.time()-tStart)/60)  } mins\\nCaluate prob ...')\n",
    "    \n",
    "    ## probability tune\n",
    "    mat = np.zeros([5,100])\n",
    "    for threshold in range(100):\n",
    "        y_pred_train = np.int_( yp_train > threshold*0.01)\n",
    "        y_pred_valid = np.int_( yp_valid > threshold*0.01)\n",
    "        mat[0,threshold] = round(threshold*0.01,2)\n",
    "        mat[1,threshold] = f1_score(y_train,y_pred_train)\n",
    "        mat[2,threshold] = f1_score(y_test,y_pred_valid) \n",
    "        mat[3,threshold] = (y_train==y_pred_train).mean()\n",
    "        mat[4,threshold] = (y_test==y_pred_valid).mean()\n",
    "        \n",
    "    # Fig1 for F1\n",
    "    sns.pointplot( x= mat[0,:],y= mat[1,:],color='r')\n",
    "    sns.pointplot( x= mat[0,:],y= mat[2,:],color='b')\n",
    "    plt.title(f'{boost_type} F1 performance',color='r')\n",
    "    plt.show()\n",
    "    \n",
    "    # Fig2 for acc\n",
    "    sns.pointplot( x= mat[0,10:],y= mat[3,10:],color='r')\n",
    "    sns.pointplot( x= mat[0,10:],y= mat[4,10:],color='b')\n",
    "    plt.title(f'{boost_type} Acc performance',color='r')\n",
    "    plt.show()\n",
    "    print('--'*20)\n",
    "    \n",
    "    # reult for best probalility\n",
    "    best_prob = round(np.argmax(mat[2,:])*0.01,2)\n",
    "    print('Valid Result:\\nprob: {}, F1 : {}, acc : {}'.\\\n",
    "          format(best_prob,max(mat[2,:]).round(3), mat[4,:][np.argmax(mat[2,:])].round(3)))\n",
    "    print('--'*20)\n",
    "    \n",
    "    # confusion matrix\n",
    "    y_pred_train = np.int_( yp_train > best_prob) \n",
    "    y_pred_valid = np.int_( yp_valid > best_prob) \n",
    "    print('Train confusion matrix')\n",
    "    display(pd.crosstab(y_train, y_pred_train,margins=True, margins_name=\"Total\" ))\n",
    "    print('--'*20)\n",
    "    print('Valid confusion matrix')\n",
    "    display(pd.crosstab(y_test,y_pred_valid,margins=True, margins_name=\"Total\" ))\n",
    "    print('--'*20)\n",
    "    \n",
    "    print('Feature Importance (Top 10)')\n",
    "    display(pd.DataFrame({'feature':feature,'gain':model.feature_importances_}).\\\n",
    "        sort_values(by='gain',ascending=False).iloc[0:10,:])\n",
    "    \n",
    "    return model,best_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-10-16T15:05:17.442Z"
    }
   },
   "outputs": [],
   "source": [
    "# Test ADASYN algorithm\n",
    "#from sklearn.preprocessing import StandardScaler\n",
    "#from imblearn.over_sampling import ADASYN\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2, stratify=y,random_state = 88)\n",
    "#std_scale = StandardScaler()\n",
    "#X_train_scaled = std_scale.fit_transform(X_train)\n",
    "#X_test_scaled = std_scale.transform(X_test)\n",
    "#adasyn = ADASYN(random_state=88)\n",
    "#X_adasyn, y_adasyn = adasyn.fit_resample(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-10-16T15:05:17.444Z"
    }
   },
   "outputs": [],
   "source": [
    "#display(pd.DataFrame({'feature':feature,'gain':model_xgb.feature_importances_}).\\\n",
    "#    sort_values(by='gain',ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-10-16T15:05:17.446Z"
    }
   },
   "outputs": [],
   "source": [
    "#df_clone = df[(df.fraud_ind.notnull())].copy().sort_values(by='locdt').reset_index()\n",
    "#myCViterator = [] \n",
    "#for train, test in TimeSeriesSplit(n_splits=5).split(df_clone.index):\n",
    "#    myCViterator.append( (train, test))\n",
    "#\n",
    "#gc.collect()\n",
    "# Grid search\n",
    "param_test1 = {\n",
    "    'max_depth':list(range(12,14,1)),\n",
    "    'min_child_weight':list(range(12,13,1)),\n",
    "    'scale_pos_weight':list(range(20,80,5))\n",
    "    }\n",
    "gsearch1 = GridSearchCV(estimator = XGBClassifier(learning_rate = 0.03 , \n",
    "                                                  n_estimators=2000, \n",
    "                                                  max_depth=5,\n",
    "                                                  tree_method = 'gpu_hist',\n",
    "                                                  n_gpus= 1,\n",
    "                                                  min_child_weight=1, gamma=0, \n",
    "                                                  subsample=0.8, \n",
    "                                                  colsample_bytree=0.8,\n",
    "                                                  objective= 'binary:logistic', nthread=-1, \n",
    "                                                  scale_pos_weight=1, \n",
    "                                                  seed=27), \n",
    "                        param_grid = param_test1, scoring='f1',iid=False, cv=myCViterator,verbose=3)\n",
    "gsearch1.fit( df_clone[feature],df_clone['fraud_ind'].values.astype('int'))\n",
    "print(gsearch1.best_params_)\n",
    "#{'max_depth': 12, 'min_child_weight': 11, 'scale_pos_weight': 70}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CV result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-10-16T15:05:17.448Z"
    }
   },
   "outputs": [],
   "source": [
    "feature = [x for x in df.columns if x not in \\\n",
    "            onehot_feature + freq_feature+['count_1','fraud_ind','locdt','locdt_tran','iterm']]\n",
    "X = df[df.fraud_ind.notnull()][feature]\n",
    "y = df[df.fraud_ind.notnull()]['fraud_ind'].values.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-10-16T15:05:17.449Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = split_data(method = 4 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-10-16T15:05:17.451Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "final_model,best_prob = model_(x_train=X_train,y_train=y_train,x_test=X_test,y_test=y_test,boost_type='xgb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-10-16T15:05:17.452Z"
    }
   },
   "outputs": [],
   "source": [
    "#final_model=model = XGBClassifier(\n",
    "#                        learning_rate = 0.03 , \n",
    "#                        tree_method = 'gpu_hist',\n",
    "#                        n_estimators=5000, \n",
    "#                        max_depth=9,\n",
    "#                        min_child_weight=1, \n",
    "#                        gamma=0, \n",
    "#                        subsample=0.8, \n",
    "#                        colsample_bytree=0.8,\n",
    "#                        objective= 'binary:logistic', \n",
    "#                        nthread=-1, \n",
    "#                        scale_pos_weight=11, \n",
    "#                        seed=27\n",
    "#                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-10-16T15:05:17.454Z"
    }
   },
   "outputs": [],
   "source": [
    "# final model\n",
    "gc.collect()\n",
    "tStart = time.time()\n",
    "final_model.fit(X,y)\n",
    "#final_model.fit(new_X,new_y)\n",
    "print(f'Use time: { np.int_((time.time()-tStart)/60)  } mins')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-10-16T15:05:17.455Z"
    }
   },
   "outputs": [],
   "source": [
    "y_prob = final_model.predict_proba( df[df.fraud_ind.isnull()][feature])[:,1]\n",
    "sns.distplot(y_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-10-16T15:05:17.456Z"
    }
   },
   "outputs": [],
   "source": [
    "submit = pd.read_csv('submission_test.csv')\n",
    "Mapping = pd.DataFrame({'txkey':df[df.fraud_ind.isnull()]['txkey'],\n",
    "                        'fraud_ind':np.int_(y_prob > 0.86 )  })\n",
    "del submit['fraud_ind']\n",
    "submit = submit.merge(Mapping,how='left',on='txkey')\n",
    "print(f'best_prob: {best_prob}')\n",
    "display(submit.fraud_ind.value_counts())\n",
    "del Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-10-16T15:05:17.458Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame([\n",
    "    (x, y) for (x, y) in zip(X.columns, final_model.feature_importances_)\n",
    "]).sort_values(by=1, ascending=False).iloc[0:20, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-10-16T15:05:17.459Z"
    }
   },
   "outputs": [],
   "source": [
    "submit.to_csv('submit_xgq6288.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-10-16T15:05:17.460Z"
    }
   },
   "outputs": [],
   "source": [
    "# record \n",
    "print(f'# {final_model.learning_rate}, {final_model.max_depth} ,{final_model.scale_pos_weight}   ,{final_model.min_child_weight}    ,{final_model.n_estimators}  ,  ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-10-16T15:05:17.462Z"
    }
   },
   "outputs": [],
   "source": [
    "# eta ,dep,scale,child,nround, cv result                             , csv          , lb        , meth, feature  \n",
    "# 0.02,15 ,15   ,1    ,5000  , (prob: 0.77, F1 : 0.781, acc : 0.994) , submit_l7698 , 0.527928  , 1   , test 1,2,5\n",
    "# 0.02,15 ,15   ,1    ,5000  , (prob: 0.78, F1 : 0.751, acc : 0.993) , submit_l5647 , 0.567554  , 1   , test 5\n",
    "# 0.03,15 ,10   ,1    ,9000  , (prob: 0.68, F1 : 0.784, acc : 0.994) , submit_l4835 , 0.544638  , 1   , test 5\n",
    "# 0.01, 5 ,10   ,3    ,9000  , (prob: 0.74, F1 : 0.730, acc : 0.993) , submit_l6260 , 0.566163  , 1   , test 5\n",
    "# 0.01, 5 ,10   ,3    ,9000  , (prob: 0.77, F1 : 0.714, acc : 0.993) , submit_l6524 , 0.574345  , 1   , -txkey + test 5\n",
    "# ------------------------------------------------  fix cv split  -------------------------------------------------------------\n",
    "# 0.01, 5 ,10   ,3    ,9000  , (prob: 0.77, F1 : 0.605, acc : 0.990) , submit_l6524 , 0.574345  , 2   , -txkey + test 5\n",
    "# 0.03, 5 ,10   ,5    ,3000  , (prob: 0.71, F1 : 0.601, acc : 0.990) , submit_x7809 , 0.579507  , 2   , -txkey + test 5\n",
    "# 0.01, 5 ,10   ,3    ,9000  , (prob: 0.81, F1 : 0.621, acc : 0.991) , submit_l5831 , 0.578424  , 2   , -txkey + test 5 + new\n",
    "# 0.01, 7 ,10   ,1    ,5000  , (prob: 0.70, F1 : 0.613, acc : 0.991) , submit_x7161 , 0.587242  , 2   , -txkey + test 5\n",
    "# -------------------------------------------------  fix loctm  ---------------------------------------------------------------\n",
    "# 0.01, 5 ,10   ,3    ,9000  , (prob: 0.79, F1 : 0.615, acc : 0.991) , submit_l6246 , 0.582314  , 2   , -txkey + test 5 + new\n",
    "# 0.01, 7 ,10   ,1    ,5000  , (prob: 0.71, F1 : 0.622, acc : 0.991) , submit_x7084 , 0.584780  , 2   , -txkey + test 5 + new2\n",
    "# ------------------------------------------------  fix cv split  -------------------------------------------------------------\n",
    "# 0.01, 5 ,10   ,3    ,9000  , (prob: 0.69, F1 : 0.466, acc : 0.990) , submit_l6246 , 0.582314  , 4   , -txkey + test 5 + new\n",
    "# 0.01, 7 ,20   ,3    ,9000  , (prob: 0.81, F1 : 0.478, acc : 0.991) , submit_l6556 , 0.562601  , 4   , test 5 + new3\n",
    "# 0.02, 5 ,10   ,5    ,5000  , (prob: 0.63, F1 : 0.463, acc : 0.989) , submit_x9470 , 0.567734  , 4   , -txkey + test 5 + new2\n",
    "# 0.01, 15,10   ,3    ,9000  , (prob: 0.63, F1 : 0.492, acc : 0.991) , submit_l7607 , 0.572729  , 4   , test 5 + new2\n",
    "# 0.01, 10,10   ,1    ,9000  , (prob: 0.22, F1 : 0.466, acc : 0.990) , submit_x9847 , 0.558851  , 4   , -txkey + test 5 + new2\n",
    "# 0.01, 8 ,10   ,1    ,9000  , (prob: 0.65, F1 : 0.494, acc : 0.991) , submit_l7228 , 0.572884  , 4   , -txkey + test 5 + new2\n",
    "# 0.01, 8 ,9    ,5    ,9000  , (prob: 0.49, F1 : 0.508, acc : 0.991) , submit_l8952 , 0.574535  , 4   , -txkey + new999\n",
    "# 0.01, 8 ,9    ,5    ,9000  , (prob: 0.60, F1 : 0.508, acc : 0.991) , submit_lq7189, 0.590527  , 4   , -txkey + new999\n",
    "# 0.01, 8 ,9    ,5    ,9000  , (prob: 0.68, F1 : 0.508, acc : 0.991) , submit_lq6489, 0.596744  , 4   , -txkey + new999\n",
    "# 0.03, 9 ,11   ,1    ,2000  , (prob: 0.22, F1 : 0.523, acc : 0.991) , submit_xg8437, 0.570375  , 4   , -txkey + new999 \n",
    "# 0.03, 9 ,11   ,1    ,5000  , (prob: 0.22, F1 : 0.531, acc : 0.992) , submit_xg6177, 0.592118  , 4   , -txkey + new999 \n",
    "# 0.03, 9 ,11   ,1    ,5000  , (prob: 0.11, F1 : 0.544, acc : 0.992) , submit_xg9081, 0.548502  , 4   , new\n",
    "# 0.01,10 ,55   ,11   ,4000  , (prob: 0.46, F1 : 0.555, acc : 0.992) , submit_xg6548, 0.575885  , 4   , new2\n",
    "# 0.03,10 ,55   ,11   ,4000  , (prob: 0.39, F1 : 0.558, acc : 0.992) , submit_xg5873, 0.581088  , 4   , new2\n",
    "# 0.03,10 ,55   ,11   ,9000  , (prob: 0.26, F1 : 0.559, acc : 0.992) , submit_xg6316, 0.586641  , 4   , new2\n",
    "\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-10-16T15:05:17.463Z"
    }
   },
   "outputs": [],
   "source": [
    "# outcome value analysis\n",
    "a = []\n",
    "for i in range(1,91):\n",
    "    a.append(df.fraud_ind[ (df.locdt==i)  ].sum())\n",
    "    \n",
    "plt.plot(a)\n",
    "print(np.array(a).mean()*30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-10-16T15:05:17.464Z"
    }
   },
   "outputs": [],
   "source": [
    "#submit1 = pd.read_csv('submit_l4835.csv')  #  0.544638\n",
    "#submit2 = pd.read_csv('submit_l6260.csv')  #  0.566163\n",
    "#submit3 = pd.read_csv('submit_l6524.csv')  #  0.574345\n",
    "#submit4 = pd.read_csv('submit_x7084.csv')  #  0.584780\n",
    "#\n",
    "#submit = pd.read_csv('submission_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-10-16T15:05:17.466Z"
    }
   },
   "outputs": [],
   "source": [
    "#submit.fraud_ind = \\\n",
    "#    (submit1.fraud_ind*0.544638 + submit2.fraud_ind*0.566163 + \n",
    "#    submit3.fraud_ind*0.574345 + submit4.fraud_ind*0.584780)  / (0.544638+0.566163+0.574345+0.584780 )\n",
    "#submit.fraud_ind = np.int_(submit.fraud_ind>=0.5)\n",
    "#submit.fraud_ind.value_counts()\n",
    "#submit.to_csv('stack1.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "515px",
    "left": "1403px",
    "right": "20px",
    "top": "42px",
    "width": "503px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
